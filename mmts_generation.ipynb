{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 20:08:20.642954: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-14 20:08:20.665515: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-14 20:08:20.665553: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-14 20:08:20.680048: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-14 20:08:22.300918: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "fname = 'agent_objects/gpt-4o/classification/Qtime_text_image_C3_B3/AtrialFibrillation.pkl'\n",
    "with open(fname, \"rb\") as f:\n",
    "    agent = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_description': 'The user wants to build a classification model to categorize ECG signals into three types of atrial fibrillation (AF) using a dataset of ECG records. The model should be deployable on wearable devices like Fitbit trackers.',\n",
       " 'data_aspects': {'name': 'PhysioNet ECG Dataset',\n",
       "  'description': 'The dataset consists of two-channel ECG recordings created from data used in the Computers in Cardiology Challenge 2004. It includes 5-second segments of atrial fibrillation, with each signal sampled at 128 samples per second.',\n",
       "  'features': 'The dataset contains two 1-D ECG signals per instance. The class labels are: n (non-terminating AF), s (self-terminating AF after at least one minute), and t (terminating immediately within one second).',\n",
       "  'context': 'The dataset was part of an open competition aimed at developing automated methods for predicting spontaneous termination of atrial fibrillation.',\n",
       "  'patterns': \"The time series plots show distinct patterns for each class. Class 'n' shows more prolonged irregularities, class 's' shows moderate irregularities, and class 't' shows quick stabilization.\"},\n",
       " 'model_aspects': {'name': 'ECG Classification Model',\n",
       "  'hardware_specs': {'device_name': 'Fitbit Tracker',\n",
       "   'ram': '512000',\n",
       "   'flash': '2000000'},\n",
       "  'MAC': '1000000',\n",
       "  'parameters': '50000',\n",
       "  'latency': '100',\n",
       "  'performance': 'High accuracy for classification of AF types'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.user_requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multimodal Time Series Generation and Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plain numerical TS\n",
    "- Basic Data Description\n",
    "- TS Image-based Description by Self-Analysis\n",
    "- TS Image (combined if multivariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils.data_desc import CLS_DATASETS, REG_DATASETS\n",
    "from utils.data_desc import data_contexts, feature_descriptions, feature_names\n",
    "from utils.data_loader import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for data_name in sorted(REG_DATASETS):\n",
    "    task = \"regression\"\n",
    "    X_train, y_train, _, _ = load_dataset(data_name, task)\n",
    "    q75, q25 = np.percentile(y_train, [75 ,25])\n",
    "    print(data_name, X_train.shape, q25, q75)\n",
    "    class_numbers = ['q1', 'iqr', 'q3']\n",
    "    for cname in class_numbers:\n",
    "        if cname == 'q1':\n",
    "            cidx = np.where(y_train <= q25)[0]\n",
    "        elif cname == 'iqr':\n",
    "            cidx = np.where((y_train > q25) & (y_train < q75))[0]\n",
    "        else:\n",
    "            cidx = np.where(y_train >= q75)[0]\n",
    "\n",
    "        # group ALL training samples into ONE sample using mean ± 2 * std as representative class samples OR bin sample for regression\n",
    "        ts_mean = np.mean(X_train[cidx], axis=0)\n",
    "        ts_std = np.std(X_train[cidx], axis=0)\n",
    "        ts_upper = ts_mean + (2 * ts_std)\n",
    "        ts_lower = ts_mean - (2 * ts_std)\n",
    "        # save values for numerical modality\n",
    "        os.makedirs(f\"ts_values/{data_name}\", exist_ok=True)\n",
    "   \n",
    "        # group ALL training samples into ONE sample using mean ± 2 * std as representative class samples OR bin sample for regression\n",
    "        ts_mean = np.mean(X_train[cidx], axis=0)\n",
    "        ts_std = np.std(X_train[cidx], axis=0)\n",
    "        ts_upper = ts_mean + (2 * ts_std)\n",
    "        ts_lower = ts_mean - (2 * ts_std)\n",
    "        t = np.arange(X_train.shape[1])\n",
    "        n_features = X_train.shape[2]\n",
    "\n",
    "        fsize = 1024 / 300\n",
    "        fig, axs = plt.subplots(n_features, 1, figsize=(fsize, fsize), dpi=300)\n",
    "        for fidx in range(n_features):\n",
    "            if n_features > 1:\n",
    "                axs[fidx].plot(t, ts_mean[:, fidx])\n",
    "                axs[fidx].fill_between(t, ts_lower[:, fidx], ts_upper[:, fidx], color=\"b\", alpha=0.1)\n",
    "                axs[fidx].set_title(feature_names[data_name][fidx])\n",
    "            else:\n",
    "                axs.plot(t, ts_mean[:, fidx])\n",
    "                axs.fill_between(t, ts_lower[:, fidx], ts_upper[:, fidx], color=\"b\", alpha=0.1)\n",
    "                axs.set_title(feature_names[data_name][fidx])\n",
    "\n",
    "        if cname == 'q1':\n",
    "            # fig.suptitle(f'Time Series Plot for Label Values \"<= {q25:.2f}\"',fontweight=\"bold\")\n",
    "            np.save(f\"ts_values/{data_name}/lower-than-{q25:.2f}_mean.npy\", ts_mean)\n",
    "            np.save(f\"ts_values/{data_name}/lower-than-{q25:.2f}_std.npy\", ts_std) \n",
    "        elif cname == 'iqr':\n",
    "            # fig.suptitle(f'Time Series Plot for Label Values \"between {q25:.2f} and {q75:.2f}\"',fontweight=\"bold\")\n",
    "            np.save(f\"ts_values/{data_name}/between-{q25:.2f}-and-{q75:.2f}_mean.npy\", ts_mean)\n",
    "            np.save(f\"ts_values/{data_name}/between-{q25:.2f}-and-{q75:.2f}_std.npy\", ts_std) \n",
    "        else:\n",
    "            # fig.suptitle(f'Time Series Plot for Label Values \">= {q75:.2f}\"',fontweight=\"bold\")\n",
    "            np.save(f\"ts_values/{data_name}/higher-than-{q75:.2f}_mean.npy\", ts_mean)\n",
    "            np.save(f\"ts_values/{data_name}/higher-than-{q75:.2f}_std.npy\", ts_std)            \n",
    "\n",
    "        plt.tight_layout()\n",
    "        os.makedirs(f\"ts_images/{data_name}\", exist_ok=True)\n",
    "        plt.savefig(f\"ts_images/{data_name}/{cname}.png\", bbox_inches=\"tight\")\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for data_name in sorted(CLS_DATASETS):\n",
    "    task = \"classification\"\n",
    "    X_train, y_train, _, _, class_names = load_dataset(data_name, task)\n",
    "    class_numbers = np.unique(y_train)\n",
    "    print(data_name, X_train.shape, class_numbers)\n",
    "    for cnum in class_numbers:\n",
    "        cidx = np.where(y_train == cnum)[0]\n",
    "        cname = class_names[cnum].replace(\".0\", \"\")\n",
    "        # group ALL training samples into ONE sample using mean ± 2 * std as representative class samples OR bin sample for regression\n",
    "        ts_mean = np.mean(X_train[cidx], axis=0)\n",
    "        ts_std = np.std(X_train[cidx], axis=0)\n",
    "        ts_upper = ts_mean + (2 * ts_std)\n",
    "        ts_lower = ts_mean - (2 * ts_std)\n",
    "        # save values for numerical modality\n",
    "        os.makedirs(f\"ts_values/{data_name}\", exist_ok=True)\n",
    "        np.save(f\"ts_values/{data_name}/{cname}_mean.npy\", ts_mean)\n",
    "        np.save(f\"ts_values/{data_name}/{cname}_std.npy\", ts_std)                \n",
    "        \n",
    "        t = np.arange(X_train.shape[1])\n",
    "        n_features = X_train.shape[2]\n",
    "\n",
    "        fsize = 1024 / 300\n",
    "        fig, axs = plt.subplots(n_features, 1, figsize=(fsize, fsize), dpi=300)\n",
    "        for fidx in range(n_features):\n",
    "            if n_features > 1:\n",
    "                axs[fidx].plot(t, ts_mean[:, fidx])\n",
    "                axs[fidx].fill_between(\n",
    "                    t, ts_lower[:, fidx], ts_upper[:, fidx], color=\"b\", alpha=0.1\n",
    "                )\n",
    "                axs[fidx].set_title(feature_names[data_name][fidx])\n",
    "            else:\n",
    "                axs.plot(t, ts_mean[:, fidx])\n",
    "                axs.fill_between(\n",
    "                    t, ts_lower[:, fidx], ts_upper[:, fidx], color=\"b\", alpha=0.1\n",
    "                )\n",
    "                axs.set_title(feature_names[data_name][fidx])\n",
    "\n",
    "        # fig.suptitle(\n",
    "        #     f'Time Series Plot for \"{cname}\" Class Label',\n",
    "        #     fontweight=\"bold\",\n",
    "        # )\n",
    "        plt.tight_layout()\n",
    "        os.makedirs(f\"ts_images/{data_name}\", exist_ok=True)\n",
    "        plt.savefig(f\"ts_images/{data_name}/{cname}.png\", bbox_inches=\"tight\")\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob('ts_values/AppliancesEnergy/*_mean.npy')[0].split('/')[-1].split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from exp_prompts import complete_by_values, complete_by_contexts, complete_by_images, complete_mm_prompt\n",
    "\n",
    "print(complete_mm_prompt(task='classification', query_type=['time', 'text', 'image'], data_name='UCIHAR'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base64\n",
    "# from configs import Configs\n",
    "# from openai import OpenAI\n",
    "\n",
    "# client = OpenAI(api_key=Configs.OPENAI_KEY)\n",
    "\n",
    "\n",
    "# # Function to encode the image\n",
    "# def encode_image(image_path):\n",
    "#     with open(image_path, \"rb\") as image_file:\n",
    "#         return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Path to your image\n",
    "# image_path = \"path_to_your_image.jpg\"\n",
    "# # Getting the base64 string\n",
    "# base64_image = encode_image(image_path)\n",
    "\n",
    "# response = client.chat.completions.create(\n",
    "#   model=\"gpt-4o-mini\",\n",
    "#   messages=[\n",
    "#     {\n",
    "#       \"role\": \"user\",\n",
    "#       \"content\": [\n",
    "#         {\n",
    "#           \"type\": \"text\",\n",
    "#           \"text\": \"What is in this image?\",\n",
    "#         },\n",
    "#         {\n",
    "#           \"type\": \"image_url\",\n",
    "#           \"image_url\": {\n",
    "#             \"url\":  f\"data:image/jpeg;base64,{base64_image}\"\n",
    "#           },\n",
    "#         },\n",
    "#       ],\n",
    "#     }\n",
    "#   ],\n",
    "# )\n",
    "\n",
    "# print(response.choices[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MONAQ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
